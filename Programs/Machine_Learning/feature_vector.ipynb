{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c785a6b-2226-471c-bd91-8ab50c872b61",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Load all csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "number_of_testers = 34\n",
    "filenames = [\"SL_LIT\", \"SL_BIG\", \"FA_LIT\", \"FA_BIG\"]\n",
    "animname = [\"VB\", \"HS\"]\n",
    "all_dfs = {}\n",
    "\n",
    "for tester in range(1, number_of_testers+1):\n",
    "    for session in range(1, 4):\n",
    "        for trial in range(1, 4):\n",
    "            for fname in filenames:\n",
    "                for anim_name in animname:\n",
    "                    key = f\"T{tester}_S{session}_TRY{trial}_{anim_name}_{fname}\"\n",
    "                    path = rf\"C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Results_csv\\Tester{tester}\\Session{session}\\Trial{trial}\\T{tester}-S{session}-TRY{trial}-{anim_name}_{fname}.csv\"\n",
    "                    try:\n",
    "                        df = pd.read_csv(path)\n",
    "                        all_dfs[key] = df\n",
    "                        print(f\"Loaded: {key}\")\n",
    "                    except FileNotFoundError:\n",
    "                        print(f\"Missing: {key}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29abfc13-1d17-45ee-99a0-1a60ccd5e132",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Fixation vector for each file\n",
    "import duckdb\n",
    "\n",
    "fpogs_vector = []\n",
    "\n",
    "# Loop through all DataFrames in the dictionary\n",
    "for key, df in all_dfs.items():\n",
    "    \n",
    "    result = duckdb.query(\"\"\"\n",
    "        SELECT \n",
    "            AVG(FPOGX) AS FPOGX, \n",
    "            AVG(FPOGY) AS FPOGY, \n",
    "            MAX(FPOGS) AS FPOGS, \n",
    "            MAX(FPOGD) AS FPOGD, \n",
    "            FPOGID\n",
    "        FROM df\n",
    "        WHERE FPOGV = '1'\n",
    "        GROUP BY FPOGID\n",
    "        ORDER BY FPOGID\n",
    "    \"\"\").to_df()\n",
    "    \n",
    "    # Extract vectors from result\n",
    "    fpogx_vector = result['FPOGX'].tolist()\n",
    "    fpogy_vector = result['FPOGY'].tolist()\n",
    "    fpogs_values = result['FPOGS'].tolist()\n",
    "    fpogd_vector = result['FPOGD'].tolist()\n",
    "    fpogid_vector = result['FPOGID'].tolist()\n",
    "    \n",
    "    # Append structured result\n",
    "    fpogs_vector.append({\n",
    "        'file_key': key,\n",
    "        'FPOGX': fpogx_vector,\n",
    "        'FPOGY': fpogy_vector,\n",
    "        'FPOGS': fpogs_values,\n",
    "        'FPOGD': fpogd_vector,\n",
    "        'FPOGID': fpogid_vector\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "fpogs_vector_df = pd.DataFrame(fpogs_vector)\n",
    "\n",
    "# Display the DataFrame\n",
    "display(fpogs_vector_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54aab104-1699-4e52-9011-53ca469b38a5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Show the fixation data in a nicer way into a csv file\n",
    "import pandas as pd\n",
    "\n",
    "# Flatten the list into a structured tabular format\n",
    "flattened_fpogs_data = []\n",
    "\n",
    "for item in fpogs_vector:\n",
    "    file_key = item['file_key']\n",
    "    for fpogid, fpogx, fpogy, fpogs, fpogd in zip(\n",
    "        item['FPOGID'], item['FPOGX'], item['FPOGY'], item['FPOGS'], item['FPOGD']\n",
    "    ):\n",
    "        flattened_fpogs_data.append({\n",
    "            'file_key': file_key,\n",
    "            'FPOGID': fpogid,\n",
    "            'FPOGX': fpogx,\n",
    "            'FPOGY': fpogy,\n",
    "            'FPOGS': fpogs,\n",
    "            'FPOGD': fpogd\n",
    "        })\n",
    "\n",
    "# Create the final DataFrame\n",
    "fpogs_table_df = pd.DataFrame(flattened_fpogs_data)\n",
    "\n",
    "# Display the table\n",
    "display(fpogs_table_df)\n",
    "\n",
    "#Create the csv \n",
    "fpogs_table_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\fixation_vector.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4aa9d0-e7b8-4688-9a9e-229414a2d656",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create the dataframe with the first column, which is the number of fixations\n",
    "feature_vectors = []\n",
    "# Loop through all files in the dataframe\n",
    "for key, df in all_dfs.items():\n",
    "    #Start from 1 because the fixation with id zero is our first fixation\n",
    "    num_fix = 1\n",
    "    if 'FPOGID' in df.columns and not df.empty:\n",
    "        # Convert to list for easier iteration\n",
    "        fix_id_series = df['FPOGID'].tolist() \n",
    "        # Check that the list is not empty\n",
    "        if fix_id_series: \n",
    "            previous_id = fix_id_series[0]\n",
    "        # Start from the second element\n",
    "        for current_id in fix_id_series[1:]:\n",
    "            if current_id != previous_id:\n",
    "                num_fix += 1\n",
    "                previous_id = current_id\n",
    "\n",
    "    # Create a feature vector with key and features\n",
    "    feature_vectors.append({\n",
    "        'file_key': key,\n",
    "        'f0': num_fix\n",
    "    })\n",
    "     \n",
    "# Create a DataFrame from all feature vectors\n",
    "feature_df = pd.DataFrame(feature_vectors)\n",
    "\n",
    "# Display the current dataset\n",
    "display(feature_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a054610-41d4-40c2-853b-ea9df043a054",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Obtain the duration of every FPOGID in a file\n",
    "import duckdb\n",
    "\n",
    "fix_duration_vector = []\n",
    "\n",
    "for fix in fpogs_vector:\n",
    "    \n",
    "    fpogd_vector = fix['FPOGD']\n",
    "    fpogid_vector = fix['FPOGID']\n",
    "\n",
    "    # Store in the feature vector list\n",
    "    fix_duration_vector.append({\n",
    "        'file_key': key,\n",
    "        'FPOGID': fpogid_vector,\n",
    "        'FPOGD': fpogd_vector\n",
    "    })\n",
    "\n",
    "# Create a final DataFrame\n",
    "fix_duration_vector_df = pd.DataFrame(fix_duration_vector)\n",
    "\n",
    "# Display the DataFrame\n",
    "display(fix_duration_vector_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22af19a8-1552-4f5a-b817-7d3ded80ee43",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Minimum fixation duration\n",
    "\n",
    "min_fix_data = []\n",
    "\n",
    "for item in fpogs_vector:\n",
    "    file_key = item['file_key']\n",
    "    fpogd_list = item['FPOGD']\n",
    "    \n",
    "    if fpogd_list:\n",
    "        min_fpogd = np.min(fpogd_list)\n",
    "    else:\n",
    "        min_fpogd = None  \n",
    "    \n",
    "    min_fix_data.append({ \n",
    "        'file_key': file_key,\n",
    "        'f1': min_fpogd\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame for easy use or merging\n",
    "min_fixation_df = pd.DataFrame(min_fix_data)\n",
    "\n",
    "feature_df = feature_df.merge(min_fixation_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4025f6a4-f1b2-4724-8a07-b503ed70c76e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Maximum fixation duration that join with the feature vector\n",
    "max_fixation_data = []\n",
    "\n",
    "for item in fpogs_vector:\n",
    "    file_key = item['file_key']\n",
    "    max_fpogd = item['FPOGD']\n",
    "\n",
    "    #Check if empty\n",
    "    if max_fpogd: \n",
    "        max_duration = max(max_fpogd)\n",
    "    else:\n",
    "        max_duration = None \n",
    "\n",
    "    max_fixation_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f2': max_duration\n",
    "    })\n",
    "\n",
    "# Create pandas DataFrame\n",
    "max_fixation_df = pd.DataFrame(max_fixation_data)\n",
    "\n",
    "feature_df = feature_df.merge(max_fixation_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2a8082-0801-4740-bcd9-a721b2701aaf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Arithmetic mean of fixation duration that join with feature vector\n",
    "mean_fixation_data = []\n",
    "\n",
    "for item in fpogs_vector:\n",
    "    file_key = item['file_key']\n",
    "    max_fpogd = item['FPOGD']\n",
    "\n",
    "    #Check if empty\n",
    "    if max_fpogd: \n",
    "        mean_duration = np.mean(max_fpogd)\n",
    "    else:\n",
    "        mean_duration = None \n",
    "\n",
    "    mean_fixation_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f3': mean_duration\n",
    "    })\n",
    "\n",
    "# Create pandas DataFrame\n",
    "mean_fixation_df = pd.DataFrame(mean_fixation_data)\n",
    "\n",
    "feature_df = feature_df.merge(mean_fixation_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714ba864-afc7-4fb7-9abf-57006a85231f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Geometric mean of fixation duration that join with feature vector\n",
    "from scipy.stats import gmean\n",
    "\n",
    "geom_mean_fixation_data = []\n",
    "\n",
    "for item in fpogs_vector:\n",
    "    file_key = item['file_key']\n",
    "    max_fpogd = item['FPOGD']\n",
    "\n",
    "    #Check if empty\n",
    "    if max_fpogd: \n",
    "        geom_mean_duration = gmean(max_fpogd)\n",
    "    else:\n",
    "        geom_mean_duration = None \n",
    "\n",
    "    geom_mean_fixation_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f4': geom_mean_duration\n",
    "    })\n",
    "\n",
    "# Create pandas DataFrame\n",
    "geom_mean_fixation_df = pd.DataFrame(geom_mean_fixation_data)\n",
    "\n",
    "feature_df = feature_df.merge(geom_mean_fixation_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb136f6-535c-4c06-a25b-eb295cb6d56a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Median of fixation duration that join with feature vector\n",
    "median_fixation_data = []\n",
    "\n",
    "for item in fpogs_vector:\n",
    "    file_key = item['file_key']\n",
    "    max_fpogd = item['FPOGD']\n",
    "\n",
    "    #Check if empty\n",
    "    if max_fpogd: \n",
    "        median_duration = np.median(max_fpogd)\n",
    "    else:\n",
    "        median_duration = None \n",
    "\n",
    "    median_fixation_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f5': median_duration\n",
    "    })\n",
    "\n",
    "# Create pandas DataFrame\n",
    "median_fixation_df = pd.DataFrame(median_fixation_data)\n",
    "\n",
    "feature_df = feature_df.merge(median_fixation_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940c4e1f-a24b-4c78-ade5-044dbb5f13be",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Standard deviation of fixation duration that join with feature vector\n",
    "std_fixation_data = []\n",
    "\n",
    "for item in fpogs_vector:\n",
    "    file_key = item['file_key']\n",
    "    max_fpogd = item['FPOGD']\n",
    "\n",
    "    #Check if empty\n",
    "    if max_fpogd: \n",
    "        std_duration = np.std(max_fpogd)\n",
    "    else:\n",
    "        std_duration = None \n",
    "\n",
    "    std_fixation_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f6': std_duration\n",
    "    })\n",
    "\n",
    "# Create pandas DataFrame\n",
    "std_fixation_df = pd.DataFrame(std_fixation_data)\n",
    "\n",
    "feature_df = feature_df.merge(std_fixation_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8b13e0-c381-4441-81dd-691513182d55",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Median absolute deviation of fixation duration that join with feature vector\n",
    "from scipy.stats import median_abs_deviation\n",
    "\n",
    "mad_fixation_data = []\n",
    "\n",
    "for item in fpogs_vector:\n",
    "    file_key = item['file_key']\n",
    "    max_fpogd = item['FPOGD']\n",
    "\n",
    "    #Check if empty\n",
    "    if max_fpogd: \n",
    "        mad_duration = median_abs_deviation(max_fpogd, scale=1)\n",
    "    else:\n",
    "        mad_duration = None \n",
    "\n",
    "    mad_fixation_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f7': mad_duration\n",
    "    })\n",
    "\n",
    "# Create pandas DataFrame\n",
    "mad_fixation_df = pd.DataFrame(mad_fixation_data)\n",
    "\n",
    "feature_df = feature_df.merge(mad_fixation_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc60d975-cdc8-4cec-88b4-7f782b9aa2af",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Skewness of fixation duration that join with feature vector\n",
    "from scipy.stats import skew\n",
    "\n",
    "skew_fixation_data = []\n",
    "\n",
    "for item in fpogs_vector:\n",
    "    file_key = item['file_key']\n",
    "    max_fpogd = item['FPOGD']\n",
    "\n",
    "    #Check if empty\n",
    "    if max_fpogd: \n",
    "        skew_duration = skew(max_fpogd)\n",
    "    else:\n",
    "        skew_duration = None \n",
    "\n",
    "    skew_fixation_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f8': skew_duration\n",
    "    })\n",
    "\n",
    "# Create pandas DataFrame\n",
    "skew_fixation_df = pd.DataFrame(skew_fixation_data)\n",
    "\n",
    "feature_df = feature_df.merge(skew_fixation_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41906f24-7527-4b78-b61c-aa0c315a6b63",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Interquartile range of fixation duration that join with feature vector\n",
    "from scipy.stats import iqr\n",
    "\n",
    "iqr_fixation_data = []\n",
    "\n",
    "for item in fpogs_vector:\n",
    "    file_key = item['file_key']\n",
    "    max_fpogd = item['FPOGD']\n",
    "\n",
    "    #Check if empty\n",
    "    if max_fpogd: \n",
    "        iqr_duration = iqr(max_fpogd)\n",
    "    else:\n",
    "        iqr_duration = None \n",
    "\n",
    "    iqr_fixation_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f9': iqr_duration\n",
    "    })\n",
    "\n",
    "# Create pandas DataFrame\n",
    "iqr_fixation_df = pd.DataFrame(iqr_fixation_data)\n",
    "\n",
    "feature_df = feature_df.merge(iqr_fixation_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fbbb3a-37b6-4c99-b899-ca97286d16e4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Kurtosis of fixation duration that join with feature vector\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "kurt_fixation_data = []\n",
    "\n",
    "for item in fpogs_vector:\n",
    "    file_key = item['file_key']\n",
    "    max_fpogd = item['FPOGD']\n",
    "\n",
    "    #Check if empty\n",
    "    if max_fpogd: \n",
    "        kurt_duration = kurtosis(max_fpogd)\n",
    "    else:\n",
    "        kurt_duration = None \n",
    "\n",
    "    kurt_fixation_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f10': kurt_duration\n",
    "    })\n",
    "\n",
    "# Create pandas DataFrame\n",
    "kurt_fixation_df = pd.DataFrame(kurt_fixation_data)\n",
    "\n",
    "feature_df = feature_df.merge(kurt_fixation_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14b1484-79ef-4940-b9a5-575359ab77f1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Distance between consecutive fixations\n",
    "#The distance is computed taking in consideration the euclidean distance from the average FPOGX and FPOGY of two consecutive fixations\n",
    "from scipy.spatial import distance\n",
    "\n",
    "fpogs_diff_vector = []\n",
    "\n",
    "for fix in fpogs_vector:\n",
    "    file_key = fix['file_key']\n",
    "    fpogid_vector = fix['FPOGID']\n",
    "    fpogx_vector = fix['FPOGX']\n",
    "    fpogy_vector = fix['FPOGY']\n",
    "\n",
    "    # Build list of consecutive FPOGID pairs \n",
    "    fpogid_pairs = []\n",
    "    for i in range(len(fpogid_vector) - 1):\n",
    "        pair = (fpogid_vector[i], fpogid_vector[i + 1])\n",
    "        fpogid_pairs.append(pair)\n",
    "\n",
    "    # Build list of consecutive Euclidean distances\n",
    "    fpogs_differences = []\n",
    "    for i in range(len(fpogx_vector) - 1):\n",
    "            point1 = [fpogx_vector[i], fpogy_vector[i]]\n",
    "            point2 = [fpogx_vector[i + 1], fpogy_vector[i + 1]]\n",
    "            dist = distance.euclidean(point1, point2)\n",
    "            fpogs_differences.append(dist)\n",
    "       \n",
    "    # Append result \n",
    "    fpogs_diff_vector.append({\n",
    "        'file_key': file_key,\n",
    "        'FPOGID_pairs': fpogid_pairs,\n",
    "        'FPOGS_differences': fpogs_differences\n",
    "    })\n",
    "\n",
    "# Create the DataFrame\n",
    "fpogs_diff_vector_df = pd.DataFrame(fpogs_diff_vector)\n",
    "\n",
    "# Display the DataFrame\n",
    "display(fpogs_diff_vector_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989635f2-0386-45a6-b207-bddef54c747e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Minimum difference between consecutive fixations that join with feature vector\n",
    "min_diff_data = []\n",
    "\n",
    "for item in fpogs_diff_vector:\n",
    "    file_key = item['file_key']\n",
    "    differences = item['FPOGS_differences']\n",
    "\n",
    "    #Check if the list is empty\n",
    "    if differences:  \n",
    "        min_diff = np.min(differences)\n",
    "    else:\n",
    "        min_diff = None\n",
    "\n",
    "    min_diff_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f11': min_diff\n",
    "    })\n",
    "\n",
    "# Create DataFrame from min differences\n",
    "min_diff_df = pd.DataFrame(min_diff_data)\n",
    "\n",
    "feature_df = feature_df.merge(min_diff_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7758b470-0797-4be2-a678-47cd2d138cb7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Maximum difference between consecutive fixations that join with feature vector\n",
    "max_diff_data = []\n",
    "\n",
    "for item in fpogs_diff_vector:\n",
    "    file_key = item['file_key']\n",
    "    differences = item['FPOGS_differences']\n",
    "\n",
    "    #Check if the list is empty\n",
    "    if differences:  \n",
    "        max_diff = np.max(differences)\n",
    "    else:\n",
    "        max_diff = None\n",
    "\n",
    "    max_diff_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f12': max_diff\n",
    "    })\n",
    "\n",
    "# Create the DataFrame \n",
    "max_diff_df = pd.DataFrame(max_diff_data)\n",
    "\n",
    "feature_df = feature_df.merge(max_diff_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b695575-a1b3-469a-aba3-70adec8f13e5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Arithmetic mean between consecutive fixations that join with feature vector\n",
    "mean_diff_data = []\n",
    "\n",
    "for item in fpogs_diff_vector:\n",
    "    file_key = item['file_key']\n",
    "    differences = item['FPOGS_differences']\n",
    "\n",
    "    #Check if the list is empty\n",
    "    if differences:  \n",
    "        mean_diff = np.mean(differences)\n",
    "    else:\n",
    "        mean_diff = None\n",
    "\n",
    "    mean_diff_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f13': mean_diff\n",
    "    })\n",
    "\n",
    "# Create the DataFrame \n",
    "mean_diff_df = pd.DataFrame(mean_diff_data)\n",
    "\n",
    "feature_df = feature_df.merge(mean_diff_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154b0faa-1a94-4b1e-ad61-df786ad8bc68",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Geometric mean between consecutive fixations that join with feature vector\n",
    "gmean_diff_data = []\n",
    "\n",
    "for item in fpogs_diff_vector:\n",
    "    file_key = item['file_key']\n",
    "    differences = item['FPOGS_differences']\n",
    "\n",
    "    #Check if the list is empty\n",
    "    if differences:  \n",
    "        gmean_diff = gmean(differences)\n",
    "    else:\n",
    "        gmean_diff = None\n",
    "\n",
    "    gmean_diff_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f14': gmean_diff\n",
    "    })\n",
    "\n",
    "# Create the DataFrame \n",
    "gmean_diff_df = pd.DataFrame(gmean_diff_data)\n",
    "\n",
    "feature_df = feature_df.merge(gmean_diff_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0d7da4-f9ed-4a6e-b31e-a31ca070d655",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Median between consecutive fixations that join with feature vector\n",
    "median_diff_data = []\n",
    "\n",
    "for item in fpogs_diff_vector:\n",
    "    file_key = item['file_key']\n",
    "    differences = item['FPOGS_differences']\n",
    "\n",
    "    #Check if the list is empty\n",
    "    if differences:  \n",
    "        median_diff = np.median(differences)\n",
    "    else:\n",
    "        median_diff = None\n",
    "\n",
    "    median_diff_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f15': median_diff\n",
    "    })\n",
    "\n",
    "# Create the DataFrame \n",
    "median_diff_df = pd.DataFrame(median_diff_data)\n",
    "\n",
    "feature_df = feature_df.merge(median_diff_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b8c038-3c5b-47ea-9190-c59ce7eb8a9f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#STD between consecutive fixations that join with feature vector\n",
    "std_diff_data = []\n",
    "\n",
    "for item in fpogs_diff_vector:\n",
    "    file_key = item['file_key']\n",
    "    differences = item['FPOGS_differences']\n",
    "\n",
    "    #Check if the list is empty\n",
    "    if differences:  \n",
    "        std_diff = np.std(differences)\n",
    "    else:\n",
    "        std_diff = None\n",
    "\n",
    "    std_diff_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f16': std_diff\n",
    "    })\n",
    "\n",
    "# Create the DataFrame \n",
    "std_diff_df = pd.DataFrame(std_diff_data)\n",
    "\n",
    "feature_df = feature_df.merge(std_diff_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4b4fb9-e7a2-4bd6-9c1c-e9180349f975",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#MAD between consecutive fixations that join with feature vector\n",
    "mad_diff_data = []\n",
    "\n",
    "for item in fpogs_diff_vector:\n",
    "    file_key = item['file_key']\n",
    "    differences = item['FPOGS_differences']\n",
    "\n",
    "    #Check if the list is empty\n",
    "    if differences:  \n",
    "        mad_diff = median_abs_deviation(differences, scale=1)\n",
    "    else:\n",
    "        mad_diff = None\n",
    "\n",
    "    mad_diff_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f17': mad_diff\n",
    "    })\n",
    "\n",
    "# Create the DataFrame \n",
    "mad_diff_df = pd.DataFrame(mad_diff_data)\n",
    "\n",
    "feature_df = feature_df.merge(mad_diff_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e731faad-b810-4319-94bd-d1cbdbfab06c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Skewness between consecutive fixations that join with feature vector\n",
    "skew_diff_data = []\n",
    "\n",
    "for item in fpogs_diff_vector:\n",
    "    file_key = item['file_key']\n",
    "    differences = item['FPOGS_differences']\n",
    "\n",
    "    #Check if the list is empty\n",
    "    if differences:  \n",
    "        skew_diff = skew(differences)\n",
    "    else:\n",
    "        skew_diff = None\n",
    "\n",
    "    skew_diff_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f18': skew_diff\n",
    "    })\n",
    "\n",
    "# Create the DataFrame \n",
    "skew_diff_df = pd.DataFrame(skew_diff_data)\n",
    "\n",
    "feature_df = feature_df.merge(skew_diff_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c521ee7-297a-40ba-8390-ca1f01dcddaf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Interquartile range between consecutive fixations that join with feature vector\n",
    "iqr_diff_data = []\n",
    "\n",
    "for item in fpogs_diff_vector:\n",
    "    file_key = item['file_key']\n",
    "    differences = item['FPOGS_differences']\n",
    "\n",
    "    #Check if the list is empty\n",
    "    if differences:  \n",
    "        iqr_diff = iqr(differences)\n",
    "    else:\n",
    "        iqr_diff = None\n",
    "\n",
    "    iqr_diff_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f19': iqr_diff\n",
    "    })\n",
    "\n",
    "# Create the DataFrame \n",
    "iqr_diff_df = pd.DataFrame(iqr_diff_data)\n",
    "\n",
    "feature_df = feature_df.merge(iqr_diff_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c575e39-7abc-4971-ae59-2f79dcacbf7f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Kurtosis between consecutive fixations that join with feature vector\n",
    "kurt_diff_data = []\n",
    "\n",
    "for item in fpogs_diff_vector:\n",
    "    file_key = item['file_key']\n",
    "    differences = item['FPOGS_differences']\n",
    "\n",
    "    #Check if the list is empty\n",
    "    if differences:  \n",
    "        kurt_diff = kurtosis(differences)\n",
    "    else:\n",
    "        kurt_diff = None\n",
    "\n",
    "    kurt_diff_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f20': kurt_diff\n",
    "    })\n",
    "\n",
    "# Create the DataFrame \n",
    "kurt_diff_df = pd.DataFrame(kurt_diff_data)\n",
    "\n",
    "feature_df = feature_df.merge(kurt_diff_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852be6a3-e872-428a-9ea3-e338fbd64d6e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Saccade vector for each file\n",
    "fpogs_saccade_vector = []\n",
    "\n",
    "# Loop through all DataFrames in the dictionary\n",
    "for key, df in all_dfs.items():\n",
    "    \n",
    "    result = duckdb.query(\"\"\"\n",
    "        SELECT \n",
    "            AVG(FPOGX) AS FPOGX, \n",
    "            AVG(FPOGY) AS FPOGY, \n",
    "            MAX(FPOGS) AS FPOGS, \n",
    "            MAX(FPOGD) AS FPOGD, \n",
    "            FPOGID\n",
    "        FROM df\n",
    "        WHERE FPOGV = '0'\n",
    "        GROUP BY FPOGID\n",
    "        ORDER BY FPOGID\n",
    "    \"\"\").to_df()\n",
    "    \n",
    "    # Extract vectors from result\n",
    "    fpogx_vector = result['FPOGX'].tolist()\n",
    "    fpogy_vector = result['FPOGY'].tolist()\n",
    "    fpogs_values = result['FPOGS'].tolist()\n",
    "    fpogd_vector = result['FPOGD'].tolist()\n",
    "    fpogid_vector = result['FPOGID'].tolist()\n",
    "    \n",
    "    # Append structured result\n",
    "    fpogs_saccade_vector.append({\n",
    "        'file_key': key,\n",
    "        'FPOGX': fpogx_vector,\n",
    "        'FPOGY': fpogy_vector,\n",
    "        'FPOGS': fpogs_values,\n",
    "        'FPOGD': fpogd_vector,\n",
    "        'FPOGID': fpogid_vector\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "fpogs_saccade_vector_df = pd.DataFrame(fpogs_saccade_vector)\n",
    "\n",
    "# Display the DataFrame\n",
    "display(fpogs_saccade_vector_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b99ba96-5e61-4445-ad8a-59956b968173",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Show the saccade data in a nicer way into a csv file\n",
    "\n",
    "# Flatten the list into a structured tabular format\n",
    "flattened_fpogs_data = []\n",
    "\n",
    "for item in fpogs_saccade_vector:\n",
    "    file_key = item['file_key']\n",
    "    for fpogid, fpogx, fpogy, fpogs, fpogd in zip(\n",
    "        item['FPOGID'], item['FPOGX'], item['FPOGY'], item['FPOGS'], item['FPOGD']\n",
    "    ):\n",
    "        flattened_fpogs_data.append({\n",
    "            'file_key': file_key,\n",
    "            'FPOGID': fpogid,\n",
    "            'FPOGX': fpogx,\n",
    "            'FPOGY': fpogy,\n",
    "            'FPOGS': fpogs,\n",
    "            'FPOGD': fpogd\n",
    "        })\n",
    "\n",
    "# Create the final DataFrame\n",
    "fpogs_table_df = pd.DataFrame(flattened_fpogs_data)\n",
    "\n",
    "# Display the table\n",
    "display(fpogs_table_df)\n",
    "\n",
    "#Create the csv \n",
    "fpogs_table_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\saccade_vector.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6c5094-cd02-49b5-a57b-efd27d1dce96",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Obtain the speed of every saccade in a file\n",
    "\n",
    "saccade_vector = []\n",
    "\n",
    "for fix in fpogs_saccade_vector:\n",
    "    file_key = fix['file_key']\n",
    "    fpogd_vector = fix['FPOGD']\n",
    "    fpogs_vector = fix['FPOGS']\n",
    "    fpogid_vector = fix['FPOGID']\n",
    "    fpogx_vector = fix['FPOGX']\n",
    "    fpogy_vector = fix['FPOGY']\n",
    "\n",
    "    # Build list of saccade speeds\n",
    "    saccade_speeds = []\n",
    "    id_pairs = []\n",
    "\n",
    "    for i in range(len(fpogs_vector) - 1):\n",
    "        #Euclidean distance between two consecutive saccades\n",
    "        point1 = [fpogx_vector[i], fpogy_vector[i]]\n",
    "        point2 = [fpogx_vector[i + 1], fpogy_vector[i + 1]]\n",
    "        dist = distance.euclidean(point1, point2)\n",
    "        \n",
    "        #Time of the saccade. It is obtained from FPOGS[i+1] - FPOGS[i] which include the time of fixation + saccade.\n",
    "        #To obtain only the saccade time I subract from this difference FPOGD[i] which is the duration of the fixation\n",
    "        diff = fpogs_vector[i + 1] - fpogs_vector[i]\n",
    "        time = diff - fpogd_vector[i]\n",
    "\n",
    "        #Compute the speed\n",
    "        if time > 0:\n",
    "            speed = dist / time\n",
    "        else:\n",
    "            speed = np.nan  \n",
    "\n",
    "        saccade_speeds.append(speed)\n",
    "        id_pairs.append((fpogid_vector[i], fpogid_vector[i + 1]))\n",
    "\n",
    "    saccade_vector.append({\n",
    "        'file_key': file_key,\n",
    "        'FPOGID_pairs': id_pairs,\n",
    "        'FPOGS_speeds': saccade_speeds\n",
    "    })\n",
    "\n",
    "saccade_vector_df = pd.DataFrame(saccade_vector)\n",
    "display(saccade_vector_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd1a91b-093d-4533-9163-48bed3f0cdb4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Minimum saccade speed\n",
    "min_speed_data = []\n",
    "\n",
    "for item in saccade_vector:\n",
    "    file_key = item['file_key']\n",
    "    speeds = item['FPOGS_speeds']\n",
    "\n",
    "    #Check if the list is empty\n",
    "    if speeds:  \n",
    "        min_speed = np.min(speeds)\n",
    "    else:\n",
    "        min_speed = None\n",
    "\n",
    "    min_speed_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f21': min_speed\n",
    "    })\n",
    "\n",
    "# Create DataFrame from min speeds\n",
    "min_speed_df = pd.DataFrame(min_speed_data)\n",
    "\n",
    "feature_df = feature_df.merge(min_speed_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1752b7-f58e-4805-b107-d7c71520206b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Maximim saccade speed\n",
    "max_speed_data = []\n",
    "\n",
    "for item in saccade_vector:\n",
    "    file_key = item['file_key']\n",
    "    speeds = item['FPOGS_speeds']\n",
    "\n",
    "    #Check if the list is empty\n",
    "    if speeds:  \n",
    "        max_speed = np.max(speeds)\n",
    "    else:\n",
    "        max_speed = None\n",
    "\n",
    "    max_speed_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f22': max_speed\n",
    "    })\n",
    "\n",
    "# Create DataFrame from max speeds\n",
    "max_speed_df = pd.DataFrame(max_speed_data)\n",
    "\n",
    "feature_df = feature_df.merge(max_speed_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf40bbc1-4ea6-437e-9efb-0559102112a0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Arithmetic mean saccade speed\n",
    "mean_speed_data = []\n",
    "\n",
    "for item in saccade_vector:\n",
    "    file_key = item['file_key']\n",
    "    speeds = item['FPOGS_speeds']\n",
    "\n",
    "    #Check if the list is empty\n",
    "    if speeds:  \n",
    "        mean_speed = np.mean(speeds)\n",
    "    else:\n",
    "        mean_speed = None\n",
    "\n",
    "    mean_speed_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f23': mean_speed\n",
    "    })\n",
    "\n",
    "# Create DataFrame from mean speeds\n",
    "mean_speed_df = pd.DataFrame(mean_speed_data)\n",
    "\n",
    "feature_df = feature_df.merge(mean_speed_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03772530-57ee-4e7c-bdc0-329f783a037c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Geometric mean saccade speed\n",
    "gmean_speed_data = []\n",
    "\n",
    "for item in saccade_vector:\n",
    "    file_key = item['file_key']\n",
    "    speeds = item['FPOGS_speeds']\n",
    "\n",
    "    #Check if the list is empty\n",
    "    if speeds:  \n",
    "        gmean_speed = gmean(speeds)\n",
    "    else:\n",
    "        gmean_speed = None\n",
    "\n",
    "    gmean_speed_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f24': gmean_speed\n",
    "    })\n",
    "\n",
    "# Create DataFrame from gmean speeds\n",
    "gmean_speed_df = pd.DataFrame(gmean_speed_data)\n",
    "\n",
    "feature_df = feature_df.merge(gmean_speed_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608f0f77-dc62-4c07-88cd-1a763d88754f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Median saccade speed\n",
    "median_speed_data = []\n",
    "\n",
    "for item in saccade_vector:\n",
    "    file_key = item['file_key']\n",
    "    speeds = item['FPOGS_speeds']\n",
    "\n",
    "    #Check if the list is empty\n",
    "    if speeds:  \n",
    "        median_speed = np.median(speeds)\n",
    "    else:\n",
    "        median_speed = None\n",
    "\n",
    "    median_speed_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f25': median_speed\n",
    "    })\n",
    "\n",
    "# Create DataFrame from median speeds\n",
    "median_speed_df = pd.DataFrame(median_speed_data)\n",
    "\n",
    "feature_df = feature_df.merge(median_speed_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06610a18-5408-44db-b620-219b69bbdcec",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#STD saccade speed\n",
    "std_speed_data = []\n",
    "\n",
    "for item in saccade_vector:\n",
    "    file_key = item['file_key']\n",
    "    speeds = item['FPOGS_speeds']\n",
    "\n",
    "    #Check if the list is empty\n",
    "    if speeds:  \n",
    "        std_speed = np.std(speeds)\n",
    "    else:\n",
    "        std_speed = None\n",
    "\n",
    "    std_speed_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f26': std_speed\n",
    "    })\n",
    "\n",
    "# Create DataFrame from std speeds\n",
    "std_speed_df = pd.DataFrame(std_speed_data)\n",
    "\n",
    "feature_df = feature_df.merge(std_speed_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7a416a-81a9-43b4-a551-adc9c1372c38",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#MAD saccade speed\n",
    "mad_speed_data = []\n",
    "\n",
    "for item in saccade_vector:\n",
    "    file_key = item['file_key']\n",
    "    speeds = item['FPOGS_speeds']\n",
    "\n",
    "    #Check if the list is empty\n",
    "    if speeds:  \n",
    "        mad_speed = median_abs_deviation(speeds, scale=1)\n",
    "    else:\n",
    "        mad_speed = None\n",
    "\n",
    "    mad_speed_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f27': mad_speed\n",
    "    })\n",
    "\n",
    "# Create DataFrame from mad speeds\n",
    "mad_speed_df = pd.DataFrame(mad_speed_data)\n",
    "\n",
    "feature_df = feature_df.merge(mad_speed_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b45dac-4849-4c74-b44d-e0681f0e75d8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Skewness saccade speed\n",
    "skew_speed_data = []\n",
    "\n",
    "for item in saccade_vector:\n",
    "    file_key = item['file_key']\n",
    "    speeds = item['FPOGS_speeds']\n",
    "\n",
    "    #Check if the list is empty\n",
    "    if speeds:  \n",
    "        skew_speed = skew(speeds)\n",
    "    else:\n",
    "        skew_speed = None\n",
    "\n",
    "    skew_speed_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f28': skew_speed\n",
    "    })\n",
    "\n",
    "# Create DataFrame from skew speeds\n",
    "skew_speed_df = pd.DataFrame(skew_speed_data)\n",
    "\n",
    "feature_df = feature_df.merge(skew_speed_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2233f157-3fa4-48d0-a8b6-574891b73a05",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#IQR saccade speed\n",
    "iqr_speed_data = []\n",
    "\n",
    "for item in saccade_vector:\n",
    "    file_key = item['file_key']\n",
    "    speeds = item['FPOGS_speeds']\n",
    "\n",
    "    #Check if the list is empty\n",
    "    if speeds:  \n",
    "        iqr_speed = iqr(speeds)\n",
    "    else:\n",
    "        iqr_speed = None\n",
    "\n",
    "    iqr_speed_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f29': iqr_speed\n",
    "    })\n",
    "\n",
    "# Create DataFrame from iqr speeds\n",
    "iqr_speed_df = pd.DataFrame(iqr_speed_data)\n",
    "\n",
    "feature_df = feature_df.merge(iqr_speed_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c753f4d-2701-4f2d-8a71-31c6e325dbfa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Kurtosis saccade speed\n",
    "kurt_speed_data = []\n",
    "\n",
    "for item in saccade_vector:\n",
    "    file_key = item['file_key']\n",
    "    speeds = item['FPOGS_speeds']\n",
    "\n",
    "    #Check if the list is empty\n",
    "    if speeds:  \n",
    "        kurt_speed = kurtosis(speeds)\n",
    "    else:\n",
    "        kurt_speed = None\n",
    "\n",
    "    kurt_speed_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f30': kurt_speed\n",
    "    })\n",
    "\n",
    "# Create DataFrame from kurt speeds\n",
    "kurt_speed_df = pd.DataFrame(kurt_speed_data)\n",
    "\n",
    "feature_df = feature_df.merge(kurt_speed_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbd9f4e-8102-4c8d-9022-f262fc85a8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scanpath lenght for every file\n",
    "#The scanpath lenght is computed summing the euclidean distance of every consecutive point in the file\n",
    "\n",
    "fpogs_scan_vector = []\n",
    "\n",
    "for fix in fpogs_vector:\n",
    "    file_key = fix['file_key']\n",
    "    fpogx_vector = fix['FPOGX']\n",
    "    fpogy_vector = fix['FPOGY']\n",
    "\n",
    "    tot = 0\n",
    "    for i in range(len(fpogx_vector) - 1):\n",
    "        point1 = [fpogx_vector[i], fpogy_vector[i]]\n",
    "        point2 = [fpogx_vector[i + 1], fpogy_vector[i + 1]]\n",
    "        dist = distance.euclidean(point1, point2)\n",
    "        tot += dist\n",
    "\n",
    "    fpogs_scan_vector.append({\n",
    "        'file_key': file_key,\n",
    "        'scanpath_length': tot\n",
    "    })\n",
    "\n",
    "fpogs_scan_vector_df = pd.DataFrame(fpogs_scan_vector)\n",
    "display(fpogs_scan_vector_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e029b9d0-7ea4-4359-90f1-0929f368c065",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#List of all valid(LPV = 1) left pupil diameter(LPD) for each file\n",
    "lpd_vector = []\n",
    "\n",
    "# Loop through all DataFrames in the dictionary\n",
    "for key, df in all_dfs.items():\n",
    "    # Query using DuckDB\n",
    "    result = duckdb.query(\"\"\"\n",
    "        SELECT LPD \n",
    "        FROM df\n",
    "        WHERE LPV = '1'\n",
    "    \"\"\").to_df()\n",
    "\n",
    "    # Extract vectors\n",
    "    lpd_list = result['LPD'].tolist()\n",
    "\n",
    "    # Append result \n",
    "    lpd_vector.append({\n",
    "        'file_key': key,\n",
    "        'LPD': lpd_list\n",
    "    })\n",
    "\n",
    "# Create the DataFrame\n",
    "lpd_vector_df = pd.DataFrame(lpd_vector)\n",
    "\n",
    "# Display the DataFrame\n",
    "display(lpd_vector_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebbfdbd-6ec2-4628-90bf-c2a45ddade80",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Minimum left pupil diameter\n",
    "min_lpd_data = []\n",
    "\n",
    "for item in lpd_vector:\n",
    "    file_key = item['file_key']\n",
    "    lpd = item['LPD']\n",
    "\n",
    "    #Check if the list is empty\n",
    "    if lpd:  \n",
    "        min_lpd = np.min(lpd)\n",
    "    else:\n",
    "        min_lpd = None\n",
    "\n",
    "    min_lpd_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f32': min_lpd\n",
    "    })\n",
    "\n",
    "# Create DataFrame from min differences\n",
    "min_lpd_df = pd.DataFrame(min_lpd_data)\n",
    "\n",
    "feature_df = feature_df.merge(min_lpd_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed31a75-86a6-4236-8cc1-6a9ccf34996a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Maximum left pupil diameter\n",
    "max_lpd_data = []\n",
    "\n",
    "for item in lpd_vector:\n",
    "    file_key = item['file_key']\n",
    "    lpd = item['LPD']\n",
    "\n",
    "    #Check if the list is empty\n",
    "    if lpd:  \n",
    "        max_lpd = np.max(lpd)\n",
    "    else:\n",
    "        max_lpd = None\n",
    "\n",
    "    max_lpd_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f33': max_lpd\n",
    "    })\n",
    "\n",
    "# Create DataFrame \n",
    "max_lpd_df = pd.DataFrame(max_lpd_data)\n",
    "\n",
    "feature_df = feature_df.merge(max_lpd_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4bd2ad-1042-4728-8d26-7ef64dd38ea1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Arithmetic mean of left pupil diameter\n",
    "mean_lpd_data = []\n",
    "\n",
    "for item in lpd_vector:\n",
    "    file_key = item['file_key']\n",
    "    lpd = item['LPD']\n",
    "\n",
    "    #Check if the list is empty\n",
    "    if lpd:  \n",
    "        mean_lpd = np.mean(lpd)\n",
    "    else:\n",
    "        mean_lpd = None\n",
    "\n",
    "    mean_lpd_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f34': mean_lpd\n",
    "    })\n",
    "\n",
    "# Create DataFrame \n",
    "mean_lpd_df = pd.DataFrame(mean_lpd_data)\n",
    "\n",
    "feature_df = feature_df.merge(mean_lpd_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db92762-7503-496b-8634-368ad0b1ff80",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Geometric mean of left pupil diameter\n",
    "gmean_lpd_data = []\n",
    "\n",
    "for item in lpd_vector:\n",
    "    file_key = item['file_key']\n",
    "    lpd = item['LPD']\n",
    "\n",
    "    #Check if the list is empty\n",
    "    if lpd:  \n",
    "        gmean_lpd = gmean(lpd)\n",
    "    else:\n",
    "        gmean_lpd = None\n",
    "\n",
    "    gmean_lpd_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f35': gmean_lpd\n",
    "    })\n",
    "\n",
    "# Create DataFrame \n",
    "gmean_lpd_df = pd.DataFrame(gmean_lpd_data)\n",
    "\n",
    "feature_df = feature_df.merge(gmean_lpd_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d60ca5-91b4-43ba-85dc-c47dffbb74dc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Median of left pupil diameter\n",
    "median_lpd_data = []\n",
    "\n",
    "for item in lpd_vector:\n",
    "    file_key = item['file_key']\n",
    "    lpd = item['LPD']\n",
    "\n",
    "    #Check if the list is empty\n",
    "    if lpd:  \n",
    "        median_lpd = np.median(lpd)\n",
    "    else:\n",
    "        median_lpd = None\n",
    "\n",
    "    median_lpd_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f36': median_lpd\n",
    "    })\n",
    "\n",
    "# Create DataFrame \n",
    "median_lpd_df = pd.DataFrame(median_lpd_data)\n",
    "\n",
    "feature_df = feature_df.merge(median_lpd_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fb038a-e200-4dea-aded-f63600a1091c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#STD of left pupil diameter\n",
    "std_lpd_data = []\n",
    "\n",
    "for item in lpd_vector:\n",
    "    file_key = item['file_key']\n",
    "    lpd = item['LPD']\n",
    "\n",
    "    #Check if the list is empty\n",
    "    if lpd:  \n",
    "        std_lpd = np.std(lpd)\n",
    "    else:\n",
    "        median_lpd = None\n",
    "\n",
    "    std_lpd_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f37': std_lpd\n",
    "    })\n",
    "\n",
    "# Create DataFrame \n",
    "std_lpd_df = pd.DataFrame(std_lpd_data)\n",
    "\n",
    "feature_df = feature_df.merge(std_lpd_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dbb188-e07a-4954-85a7-e28203a75a06",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#MAD of left pupil diameter\n",
    "mad_lpd_data = []\n",
    "\n",
    "for item in lpd_vector:\n",
    "    file_key = item['file_key']\n",
    "    lpd = item['LPD']\n",
    "\n",
    "    #Check if the list is empty\n",
    "    if lpd:  \n",
    "        mad_lpd = median_abs_deviation(lpd, scale=1)\n",
    "    else:\n",
    "        median_lpd = None\n",
    "\n",
    "    mad_lpd_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f38': mad_lpd\n",
    "    })\n",
    "\n",
    "# Create DataFrame \n",
    "mad_lpd_df = pd.DataFrame(mad_lpd_data)\n",
    "\n",
    "feature_df = feature_df.merge(mad_lpd_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce5c1eb-59b2-4347-a575-5928d8c79f2d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#SKEWNESS of left pupil diameter\n",
    "skew_lpd_data = []\n",
    "\n",
    "for item in lpd_vector:\n",
    "    file_key = item['file_key']\n",
    "    lpd = item['LPD']\n",
    "\n",
    "    #Check if the list is empty\n",
    "    if lpd:  \n",
    "        skew_lpd = skew(lpd)\n",
    "    else:\n",
    "        median_lpd = None\n",
    "\n",
    "    skew_lpd_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f39': skew_lpd\n",
    "    })\n",
    "\n",
    "# Create DataFrame \n",
    "skew_lpd_df = pd.DataFrame(skew_lpd_data)\n",
    "\n",
    "feature_df = feature_df.merge(skew_lpd_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793d6397-6424-4359-87cc-68d84d4dc9b3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#IQR of left pupil diameter\n",
    "iqr_lpd_data = []\n",
    "\n",
    "for item in lpd_vector:\n",
    "    file_key = item['file_key']\n",
    "    lpd = item['LPD']\n",
    "\n",
    "    #Check if the list is empty\n",
    "    if lpd:  \n",
    "        iqr_lpd = iqr(lpd)\n",
    "    else:\n",
    "        median_lpd = None\n",
    "\n",
    "    iqr_lpd_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f40': iqr_lpd\n",
    "    })\n",
    "\n",
    "# Create DataFrame \n",
    "iqr_lpd_df = pd.DataFrame(iqr_lpd_data)\n",
    "\n",
    "feature_df = feature_df.merge(iqr_lpd_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918a9b7d-a87d-4aef-b00a-674e0f90d0b6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Kurtosis of left pupil diameter\n",
    "kurt_lpd_data = []\n",
    "\n",
    "for item in lpd_vector:\n",
    "    file_key = item['file_key']\n",
    "    lpd = item['LPD']\n",
    "\n",
    "    #Check if the list is empty\n",
    "    if lpd:  \n",
    "        kurt_lpd = kurtosis(lpd)\n",
    "    else:\n",
    "        median_lpd = None\n",
    "\n",
    "    kurt_lpd_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f41': kurt_lpd\n",
    "    })\n",
    "\n",
    "# Create DataFrame \n",
    "kurt_lpd_df = pd.DataFrame(kurt_lpd_data)\n",
    "\n",
    "feature_df = feature_df.merge(kurt_lpd_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce6452f-7e96-4e83-963f-217a99854f50",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#List of all valid(RPV = 1) right pupil diameter(RPD) for each file\n",
    "rpd_vector = []\n",
    "\n",
    "# Loop through all DataFrames in the dictionary\n",
    "for key, df in all_dfs.items():\n",
    "    # Query using DuckDB\n",
    "    result = duckdb.query(\"\"\"\n",
    "        SELECT RPD \n",
    "        FROM df\n",
    "        WHERE RPV = '1'\n",
    "    \"\"\").to_df()\n",
    "\n",
    "    # Extract vectors\n",
    "    rpd_list = result['RPD'].tolist()\n",
    "\n",
    "    # Append result \n",
    "    rpd_vector.append({\n",
    "        'file_key': key,\n",
    "        'RPD': rpd_list\n",
    "    })\n",
    "\n",
    "# Create the DataFrame\n",
    "rpd_vector_df = pd.DataFrame(rpd_vector)\n",
    "\n",
    "# Display the DataFrame\n",
    "display(rpd_vector_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33f63b2-8e8a-42cc-bc88-8d6ac41e0cee",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Minimum right pupil diameter\n",
    "min_rpd_data = []\n",
    "\n",
    "for item in rpd_vector:\n",
    "    file_key = item['file_key']\n",
    "    rpd = item['RPD']\n",
    "\n",
    "    #Check if the list is empty\n",
    "    if rpd:  \n",
    "        min_rpd = np.min(rpd)\n",
    "    else:\n",
    "        min_rpd = None\n",
    "\n",
    "    min_rpd_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f42': min_rpd\n",
    "    })\n",
    "\n",
    "# Create DataFrame from min differences\n",
    "min_rpd_df = pd.DataFrame(min_rpd_data)\n",
    "\n",
    "feature_df = feature_df.merge(min_rpd_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72592031-3dd1-40a1-9acc-47c88a276724",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Maximum right pupil diameter\n",
    "max_rpd_data = []\n",
    "\n",
    "for item in rpd_vector:\n",
    "    file_key = item['file_key']\n",
    "    rpd = item['RPD']\n",
    "\n",
    "    #Check if the list is empty\n",
    "    if rpd:  \n",
    "        max_rpd = np.max(rpd)\n",
    "    else:\n",
    "        max_rpd = None\n",
    "\n",
    "    max_rpd_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f43': max_rpd\n",
    "    })\n",
    "\n",
    "# Create DataFrame \n",
    "max_rpd_df = pd.DataFrame(max_rpd_data)\n",
    "\n",
    "feature_df = feature_df.merge(max_rpd_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d280f5d8-80fb-4186-8baf-53711fb40b8e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Arithmetic mean of right pupil diameter\n",
    "mean_rpd_data = []\n",
    "\n",
    "for item in rpd_vector:\n",
    "    file_key = item['file_key']\n",
    "    rpd = item['RPD']\n",
    "\n",
    "    #Check if the list is empty\n",
    "    if rpd:  \n",
    "        mean_rpd = np.mean(rpd)\n",
    "    else:\n",
    "        mean_rpd = None\n",
    "\n",
    "    mean_rpd_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f44': mean_rpd\n",
    "    })\n",
    "\n",
    "# Create DataFrame \n",
    "mean_rpd_df = pd.DataFrame(mean_rpd_data)\n",
    "\n",
    "feature_df = feature_df.merge(mean_rpd_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d678af85-4e19-44cb-a2f3-8fdd693ef879",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Geometric mean of right pupil diameter\n",
    "gmean_rpd_data = []\n",
    "\n",
    "for item in rpd_vector:\n",
    "    file_key = item['file_key']\n",
    "    rpd = item['RPD']\n",
    "\n",
    "    #Check if the list is empty\n",
    "    if rpd:  \n",
    "        gmean_rpd = gmean(rpd)\n",
    "    else:\n",
    "        gmean_rpd = None\n",
    "\n",
    "    gmean_rpd_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f45': gmean_rpd\n",
    "    })\n",
    "\n",
    "# Create DataFrame \n",
    "gmean_rpd_df = pd.DataFrame(gmean_rpd_data)\n",
    "\n",
    "feature_df = feature_df.merge(gmean_rpd_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb23565-5beb-4cfe-9a7d-a1a246487df6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Median of right pupil diameter\n",
    "median_rpd_data = []\n",
    "\n",
    "for item in rpd_vector:\n",
    "    file_key = item['file_key']\n",
    "    rpd = item['RPD']\n",
    "\n",
    "    #Check if the list is empty\n",
    "    if rpd:  \n",
    "        median_rpd = np.median(rpd)\n",
    "    else:\n",
    "        median_rpd = None\n",
    "\n",
    "    median_rpd_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f46': median_rpd\n",
    "    })\n",
    "\n",
    "# Create DataFrame \n",
    "median_rpd_df = pd.DataFrame(median_rpd_data)\n",
    "\n",
    "feature_df = feature_df.merge(median_rpd_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325cd099-df04-4288-9bd0-a30eb90423ac",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#STD of right pupil diameter\n",
    "std_rpd_data = []\n",
    "\n",
    "for item in rpd_vector:\n",
    "    file_key = item['file_key']\n",
    "    rpd = item['RPD']\n",
    "\n",
    "    #Check if the list is empty\n",
    "    if rpd:  \n",
    "        std_rpd = np.std(rpd)\n",
    "    else:\n",
    "        median_rpd = None\n",
    "\n",
    "    std_rpd_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f47': std_rpd\n",
    "    })\n",
    "\n",
    "# Create DataFrame \n",
    "std_rpd_df = pd.DataFrame(std_rpd_data)\n",
    "\n",
    "feature_df = feature_df.merge(std_rpd_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aeb877-890c-4a66-9855-0bdad3ce3539",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#MAD of right pupil diameter\n",
    "mad_rpd_data = []\n",
    "\n",
    "for item in rpd_vector:\n",
    "    file_key = item['file_key']\n",
    "    rpd = item['RPD']\n",
    "\n",
    "    #Check if the list is empty\n",
    "    if rpd:  \n",
    "        mad_rpd = median_abs_deviation(rpd, scale=1)\n",
    "    else:\n",
    "        median_rpd = None\n",
    "\n",
    "    mad_rpd_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f48': mad_rpd\n",
    "    })\n",
    "\n",
    "# Create DataFrame \n",
    "mad_rpd_df = pd.DataFrame(mad_rpd_data)\n",
    "\n",
    "feature_df = feature_df.merge(mad_rpd_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68182246-5d62-495a-aff4-e86582befdc4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#SKEWNESS of right pupil diameter\n",
    "skew_rpd_data = []\n",
    "\n",
    "for item in rpd_vector:\n",
    "    file_key = item['file_key']\n",
    "    rpd = item['RPD']\n",
    "\n",
    "    #Check if the list is empty\n",
    "    if rpd:  \n",
    "        skew_rpd = skew(rpd)\n",
    "    else:\n",
    "        median_rpd = None\n",
    "\n",
    "    skew_rpd_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f49': skew_rpd\n",
    "    })\n",
    "\n",
    "# Create DataFrame \n",
    "skew_rpd_df = pd.DataFrame(skew_rpd_data)\n",
    "\n",
    "feature_df = feature_df.merge(skew_rpd_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f9eefe-1fd2-4b59-979d-ea53f896ec87",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#IQR of right pupil diameter\n",
    "iqr_rpd_data = []\n",
    "\n",
    "for item in rpd_vector:\n",
    "    file_key = item['file_key']\n",
    "    rpd = item['RPD']\n",
    "\n",
    "    #Check if the list is empty\n",
    "    if rpd:  \n",
    "        iqr_rpd = iqr(rpd)\n",
    "    else:\n",
    "        median_rpd = None\n",
    "\n",
    "    iqr_rpd_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f50': iqr_rpd\n",
    "    })\n",
    "\n",
    "# Create DataFrame \n",
    "iqr_rpd_df = pd.DataFrame(iqr_rpd_data)\n",
    "\n",
    "feature_df = feature_df.merge(iqr_rpd_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07834389-4a86-4baa-8e47-3cbf71b654ac",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Kurtosis of right pupil diameter\n",
    "kurt_rpd_data = []\n",
    "\n",
    "for item in rpd_vector:\n",
    "    file_key = item['file_key']\n",
    "    rpd = item['RPD']\n",
    "\n",
    "    #Check if the list is empty\n",
    "    if rpd:  \n",
    "        kurt_rpd = kurtosis(rpd)\n",
    "    else:\n",
    "        median_rpd = None\n",
    "\n",
    "    kurt_rpd_data.append({\n",
    "        'file_key': file_key,\n",
    "        'f51': kurt_rpd\n",
    "    })\n",
    "\n",
    "# Create DataFrame \n",
    "kurt_rpd_df = pd.DataFrame(kurt_rpd_data)\n",
    "\n",
    "feature_df = feature_df.merge(kurt_rpd_df, on='file_key', how='left')\n",
    "display(feature_df)\n",
    "\n",
    "#Overwrite the csv \n",
    "feature_df.to_csv(r'C:\\Users\\david\\OneDrive\\Documenti\\Tesi_BehavBio\\Programs\\Feature_csv\\feature_vector.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
